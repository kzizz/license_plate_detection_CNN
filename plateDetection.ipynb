{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import cv2\n",
    "import os\n",
    "import errno\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "inputWidth = 18\n",
    "inputHeight = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# You will need to update this path to match the folder in your Google Drive\n",
    "PATH = \"./pictures\"\n",
    "croppedPath = \"./cropped\"\n",
    "# labels = !ls \"{PATH}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x0 = 50\n",
    "y0 = 80\n",
    "spaceX = 5\n",
    "spaceFlagX = 105\n",
    "dy = 170\n",
    "dx = 95\n",
    "x1 = x0 + spaceX + dx\n",
    "x2 = x1 + spaceFlagX + dx\n",
    "x3 = x2 + spaceX + dx\n",
    "x4 = x3 + spaceX + dx\n",
    "n = 0\n",
    "fileNames = []\n",
    "\n",
    "for file in os.listdir(PATH):\n",
    "    if(file.endswith('.png')):\n",
    "        cropPath = []\n",
    "        for i in range(4):\n",
    "            cropPath.append(file[6+i])\n",
    "        image = cv2.imread(PATH + '/' + file) #converts to grey scale\n",
    "        grayImage = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        crop_img1 = 255 - grayImage[y0:y0+dy, x0:x0+dx]\n",
    "        #crop_img1 = np.expand_dims(crop_img1, axis=2)\n",
    "        crop_img2 = 255 - grayImage[y0:y0+dy, x1:x1+dx]\n",
    "        #crop_img2 = np.expand_dims(crop_img2, axis=2)\n",
    "        crop_img3 = 255 - grayImage[y0:y0+dy, x2:x2+dx]\n",
    "        #crop_img3 = np.expand_dims(crop_img3, axis=2)\n",
    "        crop_img4 = 255 - grayImage[y0:y0+dy, x3:x3+dx]\n",
    "        #crop_img4 = np.expand_dims(crop_img4, axis=2)\n",
    "        fileName1 = cropPath[0] + str(n) + '.png'\n",
    "        fileName2 = cropPath[1] + str(n) + '.png'\n",
    "        fileName3 = cropPath[2] + str(n) + '.png'\n",
    "        fileName4 = cropPath[3] + str(n) + '.png'\n",
    "        fileNames.extend([fileName1, fileName2, fileName3, fileName4])\n",
    "        cv2.imwrite(croppedPath +'/'+ fileName1,crop_img1)\n",
    "        cv2.imwrite(croppedPath +'/' + fileName2,crop_img2)\n",
    "        cv2.imwrite(croppedPath +'/' + fileName3,crop_img3)\n",
    "        cv2.imwrite(croppedPath +'/' + fileName4,crop_img4)\n",
    "        \n",
    "        n = n+1\n",
    "# shuffle data\n",
    "random.shuffle(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary\n",
    "\n",
    "labels = ['0','1','2','3','4','5','6','7','8','9']\n",
    "labels.extend(list(string.ascii_uppercase))\n",
    "dictionary = {\"image\" : [] , \"vector\": [], \"label\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in fileNames:\n",
    "    pathToImage = croppedPath + '/' + fileName\n",
    "    label = fileName[0]\n",
    "    index = labels.index(label)\n",
    "    #creating the vector\n",
    "    vec = [0] * 36\n",
    "    vec[index] = 1\n",
    "    img = cv2.imread(pathToImage)\n",
    "    img = cv2.resize(img,(inputWidth,inputHeight))\n",
    "#     imgAugmented = np.expand_dims(img, axis=0)\n",
    "#     plt.imshow(imgAugmented)\n",
    "    dictionary[\"image\"].append(img/255.0) #normalizing to values between zero and one\n",
    "    dictionary[\"vector\"].append(vec)\n",
    "    dictionary[\"label\"].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX=100\n",
    "\n",
    "plt.imshow(dictionary[\"image\"][INDEX])\n",
    "# print(dictionary[\"image\"][INDEX])\n",
    "print(dictionary[\"vector\"][INDEX])\n",
    "print(len(dictionary[\"vector\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the system\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(dictionary[\"image\"])\n",
    "y_train = np.array(dictionary[\"vector\"])                   \n",
    "\n",
    "def blur(image):\n",
    "    kernelSize = random.randrange(1, 5+1, 2)\n",
    "    return cv2.GaussianBlur(image,(kernelSize,kernelSize),cv2.BORDER_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blur(dictionary[\"image\"][INDEX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "datagen = ImageDataGenerator(\n",
    "                              brightness_range=[0.2,1.0],\n",
    "                               rotation_range = 1,\n",
    "                               zoom_range = [0.8,1],\n",
    "                              validation_split = 0.2,\n",
    "                             width_shift_range = 0.1,\n",
    "                              height_shift_range = 0.1,\n",
    "                             shear_range=0.2,\n",
    "                            preprocessing_function = blur\n",
    "                            )\n",
    "training_generator = datagen.flow(x_train,y_train,batch_size=64,subset='training')\n",
    "validation_generator = datagen.flow(x_train, y_train, batch_size=64,subset='validation')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(6):\n",
    "     plt.subplot(2,3,i+1)\n",
    "    for x,y in training_generator:\n",
    "        plt.imshow((x[0]/255),cmap='gray')\n",
    "#       plt.title('y={}'.format(y[0]))\n",
    "        plt.axis('off')\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import sys\n",
    "# import time\n",
    "# import random\n",
    "\n",
    "\n",
    "# imgWidth = 95\n",
    "# imgHeight = 170\n",
    "\n",
    "# def augmentImage(image):\n",
    "#     distortedImage = 0\n",
    "#     # possible operations\n",
    "#     # color distortion, random blur, shear transform, decrease resolution\n",
    "#     possibleResolutions = [10]\n",
    "#     possibleBlurs = [3]\n",
    "#     possibleChannels = [cv2.COLOR_BGR2HSV,cv2.COLOR_BGR2GRAY,'BGR'] #or keep BGR\n",
    "#     possibleOperations = [possibleResolutions,possibleBlurs,possibleChannels]\n",
    "#     possibleFunctions = [lowerResolution,blur,changeColorChannel]\n",
    "#     for index,operation in enumerate(possibleOperations):\n",
    "#         numberOfOptions = len(operation)\n",
    "#         randomOperation = operation[random.randint(0,numberOfOptions-1)]\n",
    "#         distortedImage = possibleFunctions[index](image,randomOperation)\n",
    "#     return distortedImage\n",
    "# def changeColorChannel(image,channel):\n",
    "#     print(\"color channel\")\n",
    "#     print(channel)\n",
    "#     if(channel != 'BGR'):\n",
    "#         print(\"changed color channel\")\n",
    "#         newImage = cv2.cvtColor(image,channel)\n",
    "#     else:\n",
    "#         newImage = image\n",
    "#     return newImage\n",
    "        \n",
    "# # lowers the resolution of the image\n",
    "# def blur(image,kernelVal):\n",
    "#     print(kernelVal)\n",
    "#     return cv2.GaussianBlur(image,(kernelVal,kernelVal),cv2.BORDER_DEFAULT)\n",
    "\n",
    "# def lowerResolution(frame, percent):\n",
    "#     print(\"lowered resolution by\")\n",
    "#     print(percent)\n",
    "#     width = int(frame.shape[1] * percent/ 100)\n",
    "#     height = int(frame.shape[0] * percent/ 100)\n",
    "#     dim = (width, height)\n",
    "#     resizedImage = cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "# #     lowResImage = cv2.resize(resizedImage,(imgWidth,imgHeight))\n",
    "#     plt.imshow(lowResImage)\n",
    "#     return resizedImage\n",
    "# # plt.imshow(dictionary[\"image\"][INDEX])\n",
    "# image = augmentImage(dictionary[\"image\"][INDEX])\n",
    "# plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    session = backend.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = models.Sequential()\n",
    "conv_model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                             input_shape=(inputHeight,inputWidth, 3)))\n",
    "conv_model.add(layers.MaxPooling2D((2, 2)))\n",
    "conv_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "conv_model.add(layers.MaxPooling2D((2, 2), padding = 'same'))\n",
    "conv_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "conv_model.add(layers.MaxPooling2D((2, 2), padding = 'same'))\n",
    "# conv_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# conv_model.add(layers.MaxPooling2D((2, 2), padding = 'same'))\n",
    "conv_model.add(layers.Flatten())\n",
    "conv_model.add(layers.Dropout(0.5))\n",
    "conv_model.add(layers.Dense(512, activation='relu'))\n",
    "conv_model.add(layers.Dense(36, activation='softmax'))     \n",
    "\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-84b4345809d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m conv_model.compile(loss='categorical_crossentropy',\n\u001b[0m\u001b[1;32m      3\u001b[0m                    \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    metrics=['acc'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_model' is not defined"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "conv_model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=optimizers.RMSprop(lr=LEARNING_RATE),\n",
    "                   metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reset_weights(conv_model)\n",
    "# history_conv = conv_model.fit(np.array(dictionary[\"image\"]), np.array(dictionary[\"vector\"]), \n",
    "#                               validation_data = (np.array(dictionary[\"image\"]), np.array(dictionary[\"vector\"])), \n",
    "#                               epochs=20, \n",
    "#                               batch_size=8)\n",
    "\n",
    "history_conv = conv_model.fit_generator(training_generator,steps_per_epoch=(len(x_train)*0.8)//64, epochs=60, validation_data=validation_generator, validation_steps=(len(x_train)*0.2)//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history_conv.history['loss'])\n",
    "plt.plot(history_conv.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss', 'val loss'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_conv.history['acc'])\n",
    "plt.plot(history_conv.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy (%)')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train accuracy', 'val accuracy'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "conv_model.save(\"plateModel.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fizzer/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fizzer/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 20, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 1, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                18468     \n",
      "=================================================================\n",
      "Total params: 177,764\n",
      "Trainable params: 177,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reload model for further training\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "loaded_model = load_model('plateModel.h5')\n",
    "# summarize model.\n",
    "loaded_model.summary()\n",
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# confusion = []\n",
    "# for i in range(0,len(dictionary[\"image\"])-1):\n",
    "#     img_aug = np.expand_dims(dictionary[\"image\"][i], axis=0)\n",
    "#     y_predict = conv_model.predict(img_aug)\n",
    "#     confusion.append(abs(y_predict - dictionary[\"vector\"][i]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-65289e595711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m    \u001b[0mconfused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdisplayImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfused\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-65289e595711>\u001b[0m in \u001b[0;36mdisplayImage\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplayImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#   img = cv2.blur(img,(19,19))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#   img =  rotateImage(img,4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# # Display images in the training data set. \n",
    "# def rotateImage(image, angle):\n",
    "#   image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "#   rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "#   result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "#   return result\n",
    "\n",
    "confused = []\n",
    "\n",
    "\n",
    "def displayImage(index):\n",
    "  img = x_train[index]\n",
    "#   img = cv2.blur(img,(19,19))\n",
    "#   img =  rotateImage(img,4)\n",
    "  img_aug = np.expand_dims(img, axis=0)\n",
    "  y_predict = conv_model.predict(img_aug)[0]\n",
    "#   print(y_predict)\n",
    "  plt.imshow(img)\n",
    "  predictVal = max(y_predict)\n",
    "#   print(predictVal)\n",
    "  predictedVal_index = np.where(y_predict == predictVal)[0][0]\n",
    "  predictedVal = labels[predictedVal_index]\n",
    "  groundTruth_index = np.where(y_train[index] == 1)[0][0]\n",
    "  groundTruth = labels[groundTruth_index]\n",
    "#   print(\"predicted value:\",format(predictedVal))\n",
    "#   print(\"ground truth:\",format(groundTruth))\n",
    "#   print(\"hi\")    \n",
    "  if (predictedVal != groundTruth):\n",
    "   print(\"predicted value:\",format(predictedVal))\n",
    "   print(\"ground truth:\",format(groundTruth))\n",
    "   confused.append(1)\n",
    "for i in range(2000):\n",
    "    displayImage(i)\n",
    "print(len(confused))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a2180bdccf08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrayImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernelSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernelSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBORDER_DEFAULT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m realDataGen = ImageDataGenerator(\n\u001b[0m\u001b[1;32m      6\u001b[0m                               \u001b[0mbrightness_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mrotation_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "def blurData(grayImage):\n",
    "    kernelSize = random.randrange(1, 3+1, 2)\n",
    "    return cv2.GaussianBlur(grayImage,(kernelSize,kernelSize),cv2.BORDER_DEFAULT)\n",
    "\n",
    "realDataGen = ImageDataGenerator(\n",
    "                              brightness_range=[0.8,1.0],\n",
    "                              rotation_range = 10,\n",
    "                              zoom_range = [0.8,1],\n",
    "#                               validation_split = 0.2,\n",
    "#                               width_shift_range = 0.2,\n",
    "#                              height_shift_range = 0.2,\n",
    "                             shear_range=0.2,\n",
    "#                              validation_split = 0.2,\n",
    "                             preprocessing_function = blurData\n",
    "    \n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second round of training with real data from the world\n",
    "dataDictionary = {\"image\" : [] , \"vector\": [], \"label\": []}\n",
    "dataPath = \"./realData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n",
      "(22, 18, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for file in os.listdir(numberDataPath):\n",
    "    if(file.endswith('.png')):\n",
    "        image = cv2.imread(dataPath + '/' + file)\n",
    "        image = cv2.resize(image,(inputWidth,inputHeight))\n",
    "#         print(image.shape)\n",
    "        grayImage = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        grayImage3 = np.repeat(grayImage[..., np.newaxis], 3, -1)\n",
    "        print(grayImage3.shape)\n",
    "        \n",
    "#         imageBlur = cv2.GaussianBlur(image,(11,11),cv2.BORDER_DEFAULT)\n",
    "        dataLabel = file[0]\n",
    "        #creating the vector\n",
    "        vec = [0] * 36\n",
    "        index = labels.index(dataLabel)\n",
    "        vec[index] = 1\n",
    "#         print(grayImage)\n",
    "        dataDictionary[\"image\"].append(grayImage3/255.0)#?\n",
    "        dataDictionary[\"vector\"].append(vec)\n",
    "        dataDictionary[\"label\"].append(dataLabel)\n",
    "        plt.imshow(grayImage3)\n",
    "#         print(grayImage3)\n",
    "#data augmentation\n",
    "datax_train = np.array(dataDictionary[\"image\"])\n",
    "datay_train = np.array(dataDictionary[\"vector\"])\n",
    "\n",
    "def blurData(grayImage):\n",
    "    kernelSize = random.randrange(1, 3+1, 2)\n",
    "    return cv2.GaussianBlur(grayImage,(kernelSize,kernelSize),cv2.BORDER_DEFAULT)\n",
    "\n",
    "realDataGen = ImageDataGenerator(\n",
    "                              brightness_range=[0.8,1.0],\n",
    "                              rotation_range = 10,\n",
    "                              zoom_range = [0.8,1],\n",
    "#                               validation_split = 0.2,\n",
    "#                               width_shift_range = 0.2,\n",
    "#                              height_shift_range = 0.2,\n",
    "                             shear_range=0.2,\n",
    "#                              validation_split = 0.2,\n",
    "                             preprocessing_function = blurData\n",
    "    \n",
    "                            )\n",
    "data_training_generator = realDataGen.flow(datax_train,datay_train,batch_size=64)\n",
    "# validation_generator = realDataGen.flow(datax_train, datay_train, batch_size=64,subset='validation')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    for x,y in data_training_generator:\n",
    "        plt.imshow((x[0]/255),cmap='gray')\n",
    "#         plt.title('y={}'.format(y[0]))\n",
    "        plt.axis('off')\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "len(datax_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 2.7495 - acc: 0.6406 - val_loss: 1.3720 - val_acc: 0.8211\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 3.5258 - acc: 0.5161 - val_loss: 0.4138 - val_acc: 0.8316\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5228 - acc: 0.6774 - val_loss: 0.8221 - val_acc: 0.8737\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.7943 - acc: 0.7031 - val_loss: 0.2671 - val_acc: 0.8211\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.0224 - acc: 0.6452 - val_loss: 0.3781 - val_acc: 0.8316\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.9713 - acc: 0.6250 - val_loss: 1.3188 - val_acc: 0.8316\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.3185 - acc: 0.6719 - val_loss: 1.8101 - val_acc: 0.8632\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.0889 - acc: 0.6129 - val_loss: 0.4978 - val_acc: 0.8526\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7424 - acc: 0.7742 - val_loss: 0.0715 - val_acc: 0.8526\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.1229 - acc: 0.7500 - val_loss: 1.8894 - val_acc: 0.8947\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 2.6324 - acc: 0.6452 - val_loss: 1.5657 - val_acc: 0.8947\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7819 - acc: 0.7500 - val_loss: 0.9308 - val_acc: 0.8632\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8741 - acc: 0.8710 - val_loss: 0.6727 - val_acc: 0.8842\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.1230 - acc: 0.6875 - val_loss: 1.1633 - val_acc: 0.8842\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6585 - acc: 0.8065 - val_loss: 0.6245 - val_acc: 0.8842\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9123 - acc: 0.7812 - val_loss: 1.8547 - val_acc: 0.8842\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.9798 - acc: 0.7742 - val_loss: 0.0728 - val_acc: 0.9053\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0914 - acc: 0.7188 - val_loss: 0.8013 - val_acc: 0.9158\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.3373 - acc: 0.7031 - val_loss: 0.3314 - val_acc: 0.8842\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7281 - acc: 0.8387 - val_loss: 0.3618 - val_acc: 0.9158\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7349 - acc: 0.8125 - val_loss: 0.7525 - val_acc: 0.9158\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.7919 - acc: 0.6774 - val_loss: 0.6078 - val_acc: 0.9158\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.2222 - acc: 0.7500 - val_loss: 0.1708 - val_acc: 0.9158\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4914 - acc: 0.8710 - val_loss: 0.1346 - val_acc: 0.9053\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.4746 - acc: 0.7097 - val_loss: 0.5339 - val_acc: 0.9579\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6625 - acc: 0.7812 - val_loss: 0.1236 - val_acc: 0.9263\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.2673 - acc: 0.6774 - val_loss: 0.4865 - val_acc: 0.9158\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9587 - acc: 0.7031 - val_loss: 0.1937 - val_acc: 0.9158\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4134 - acc: 0.8387 - val_loss: 0.1260 - val_acc: 0.9263\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9408 - acc: 0.7344 - val_loss: 0.5171 - val_acc: 0.9263\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7494 - acc: 0.7419 - val_loss: 0.8139 - val_acc: 0.8737\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.1293 - acc: 0.7812 - val_loss: 0.2198 - val_acc: 0.8947\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8017 - acc: 0.7969 - val_loss: 0.1893 - val_acc: 0.9263\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.5474 - acc: 0.7742 - val_loss: 0.2270 - val_acc: 0.8947\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4933 - acc: 0.8125 - val_loss: 0.1522 - val_acc: 0.9263\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7526 - acc: 0.7097 - val_loss: 0.2128 - val_acc: 0.9263\n",
      "Epoch 37/60\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.3226 - acc: 0.6562 - val_loss: 0.0836 - val_acc: 0.9158\n",
      "Epoch 38/60\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7911 - acc: 0.8065 - val_loss: 0.2437 - val_acc: 0.9158\n",
      "Epoch 39/60\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6287 - acc: 0.7969 - val_loss: 0.6182 - val_acc: 0.9368\n",
      "Epoch 40/60\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9938 - acc: 0.6774 - val_loss: 0.2928 - val_acc: 0.9263\n",
      "Epoch 41/60\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7662 - acc: 0.7097 - val_loss: 0.8951 - val_acc: 0.9263\n",
      "Epoch 42/60\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7533 - acc: 0.8438 - val_loss: 0.4361 - val_acc: 0.9158\n",
      "Epoch 43/60\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3474 - acc: 0.8710 - val_loss: 0.1941 - val_acc: 0.9053\n",
      "Epoch 44/60\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7782 - acc: 0.7500 - val_loss: 0.2111 - val_acc: 0.9158\n",
      "Epoch 45/60\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8582 - acc: 0.7419 - val_loss: 0.2227 - val_acc: 0.9263\n",
      "Epoch 46/60\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9120 - acc: 0.7812 - val_loss: 0.3710 - val_acc: 0.9158\n",
      "Epoch 47/60\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.5205 - acc: 0.8594 - val_loss: 0.3609 - val_acc: 0.9474\n",
      "Epoch 48/60\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7937 - acc: 0.7419 - val_loss: 0.7059 - val_acc: 0.9263\n",
      "Epoch 49/60\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6844 - acc: 0.7812 - val_loss: 0.1331 - val_acc: 0.9368\n",
      "Epoch 50/60\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9920 - acc: 0.8065 - val_loss: 0.1597 - val_acc: 0.9263\n",
      "Epoch 51/60\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4992 - acc: 0.8065 - val_loss: 0.1620 - val_acc: 0.9158\n",
      "Epoch 52/60\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9868 - acc: 0.7344 - val_loss: 0.2413 - val_acc: 0.9158\n",
      "Epoch 53/60\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8089 - acc: 0.7969 - val_loss: 0.4946 - val_acc: 0.9368\n",
      "Epoch 54/60\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.8768 - acc: 0.7742 - val_loss: 0.4726 - val_acc: 0.9684\n",
      "Epoch 55/60\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7851 - acc: 0.8065 - val_loss: 0.1836 - val_acc: 0.9263\n",
      "Epoch 56/60\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.5519 - acc: 0.7969 - val_loss: 0.1408 - val_acc: 0.9053\n",
      "Epoch 57/60\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6776 - acc: 0.8125 - val_loss: 0.0771 - val_acc: 0.9474\n",
      "Epoch 58/60\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.5028 - acc: 0.7097 - val_loss: 0.1521 - val_acc: 0.9684\n",
      "Epoch 59/60\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.5009 - acc: 0.8750 - val_loss: 0.3101 - val_acc: 0.9474\n",
      "Epoch 60/60\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4513 - acc: 0.8387 - val_loss: 0.3245 - val_acc: 0.9158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loaded_history = loaded_model.fit_generator(data_training_generator,steps_per_epoch=(len(datax_train)*0.8)//64, epochs=60, validation_data=data_training_generator, validation_steps=(len(datax_train)*0.2)//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#save the trained model\n",
    "loaded_model.save(\"modelWithRealData.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fizzer/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fizzer/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 20, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 1, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                18468     \n",
      "=================================================================\n",
      "Total params: 177,764\n",
      "Trainable params: 177,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reload model for further training\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "loaded_model = load_model('modelWithRealData.h5')\n",
    "# summarize model.\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('predicted value:', 'Z')\n",
      "('ground truth:', '2')\n",
      "('predicted value:', '5')\n",
      "('ground truth:', 'S')\n",
      "('predicted value:', 'S')\n",
      "('ground truth:', '0')\n",
      "('predicted value:', '1')\n",
      "('ground truth:', 'I')\n",
      "('predicted value:', 'Z')\n",
      "('ground truth:', '4')\n",
      "('predicted value:', 'B')\n",
      "('ground truth:', '8')\n",
      "('predicted value:', 'W')\n",
      "('ground truth:', '0')\n",
      "('predicted value:', '6')\n",
      "('ground truth:', '0')\n",
      "('predicted value:', 'N')\n",
      "('ground truth:', '0')\n",
      "('predicted value:', 'B')\n",
      "('ground truth:', '8')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def testModel(img,truth):\n",
    "  grayImg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "  img_aug = np.repeat(grayImg[..., np.newaxis], 3, -1)\n",
    "  img_aug = cv2.resize(img_aug,(inputWidth,inputHeight))\n",
    "  img_aug = np.expand_dims(img_aug, axis=0)\n",
    "  y_predict = loaded_model.predict(img_aug)[0]\n",
    "#   print(y_predict)\n",
    "  plt.imshow(img)\n",
    "  predictVal = max(y_predict)\n",
    "#   print(predictVal)\n",
    "  predictedVal_index = np.where(y_predict == predictVal)[0][0]\n",
    "  predictedVal = labels[predictedVal_index]\n",
    "#   groundTruth_index = np.where(datay_train[index] == 1)[0][0]\n",
    "#   groundTruth = labels[groundTruth_index]\n",
    "#   print(\"predicted value:\",format(predictedVal))\n",
    "#   print(\"ground truth:\",format(truth))\n",
    "  if (predictedVal != truth):\n",
    "   print(\"predicted value:\",format(predictedVal))\n",
    "   print(\"ground truth:\",format(truth))\n",
    "\n",
    "\n",
    "dataPath = \"./realData\"\n",
    "minWidth = 4000\n",
    "minHeight = 4000\n",
    "for file in os.listdir(dataPath):\n",
    "    if(file.endswith('.png')):\n",
    "        truth = file[0]\n",
    "        image = cv2.imread(dataPath + '/' + file) #converts to grey scale\n",
    "        width, height, dim = image.shape\n",
    "#         image = cv2.resize(image,(95,170))\n",
    "        plt.imshow(image)\n",
    "        testModel(image,truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_frame(frame, percent=75):\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "newImg = rescale_frame(dictionary[\"image\"][INDEX],10)\n",
    "plt.imshow(newImg)\n",
    "plt.imshow(cv2.resize(newImg,(95,170)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
